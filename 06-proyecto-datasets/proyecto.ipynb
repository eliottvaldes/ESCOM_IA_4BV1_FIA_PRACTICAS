{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESCOM - IIA\n",
    "#### FUNDAMENTOS DE INTELIGENCIA ARTIFICIAL - PROYECTO ML\n",
    "#### Semestre 2023-2 - Grupo 4BV2\n",
    "--- \n",
    "##### Autores:\n",
    "- **Valdés Luis Eliot Fabián**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos la librerias necesarias\n",
    "from ucimlrepo import fetch_ucirepo  # libreria de repositorios de datasets\n",
    "import pandas as pd  # libreria para el manejo de dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# PASO 1: Carga de datos\n",
    "Sección inicial para obtener el dataset, describirlo de manera general usando estadisticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos los datasets a utilizar\n",
    "datasets = {\n",
    "    \"Eliot\": 53, # Iris\n",
    "    \"Ethel\": 728, # \n",
    "    \"Leo\": 878, # Cirrhosis\n",
    "    \"Adair\": 109, # Wine\n",
    "}\n",
    "dataset = fetch_ucirepo(id=datasets[\"Leo\"]) # cargamos el dataset que deseemos utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostramos un pequeño resumen de lo que trata el dataset \n",
    "dataset.metadata.abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtenemos los datos\n",
    "X = dataset.data.features \n",
    "y = dataset.data.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos un dataframe con los datos\n",
    "df = pd.DataFrame(X, columns=dataset.data.feature_names)\n",
    "# agregamos la columna target\n",
    "df['target'] = y\n",
    "\n",
    "# mostramos la cantidad de registros\n",
    "print(f'Cantidad de registros: {len(df)}')\n",
    "\n",
    "# imprimimos los primeros 5 registros\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostramos los tipos de datos de cada columna\n",
    "print(f\"Tipos de datos (Metodo pandas):\\n{df.dtypes}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostramos los tipos de datos usando los metodos de la librearia de repositorios\n",
    "dataframe_tipos = pd.DataFrame({'Variable Name': dataset.variables['name'], 'Type': dataset.variables['type']})\n",
    "print(f\"Tipos de datos (Metodo ucimlrepo):\\n{dataframe_tipos}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# por cada columna hacer lo siguiente \n",
    "# si el tipo de dato es numerico, mostrar la media, mediana, desviacion estandar, minimo y maximo\n",
    "# si el tipo de dato es categorico, mostrar la cantidad de valores unicos\n",
    "\n",
    "# limitamos la cantidad de columnas a 10\n",
    "for col in df.columns[:10]:\n",
    "    if df[col].dtype == 'float64' or df[col].dtype == 'int64':\n",
    "        print(f\"=> '{col}':\")\n",
    "        print(f\"\\t-Media: {df[col].mean()}\")\n",
    "        print(f\"\\t-Mediana: {df[col].median()}\")\n",
    "        print(f\"\\t-Desviacion estandar: {df[col].std()}\")\n",
    "        print(f\"\\t-Minimo: {df[col].min()}\")\n",
    "        print(f\"\\t-Maximo: {df[col].max()}\")\n",
    "    else:\n",
    "        print(f\"=> '{col}':\")\n",
    "        print(f\"\\t-Valores unicos: {df[col].unique()}\")\n",
    "        print(f\"\\t-Cantidad de valores unicos: {df[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# PASO 2: PREPROCESAMIENTO DE DATOS\n",
    "\n",
    "Sección para preprocesar los datos, aquí separamos el dataset en los vectores de entrada X & de salida Y(las clases que son definidas con tipo de dato categorico)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion para separar cualquier dataframe en dos vectores (entrada y salida)\n",
    "def separate_dataframe(df):\n",
    "    vector_x = df.drop(df.columns[-1], axis=1) # obtencion de variables de entrada\n",
    "    vector_y = df[df.columns[-1]] # obtencion de variable de salida (clase/target)\n",
    "    return vector_x, vector_y\n",
    "\n",
    "# separamos el dataframe en dos vectores, uno con las variables independientes y otro con la variable dependiente\n",
    "vector_x, vector_y = separate_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostramos los primeros 5 registros del vector de entrada X\n",
    "vector_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostramos los primeros 5 registros del vector de salida Y\n",
    "vector_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos una funcion que recibe como parametros el vector de entrada X y el vector de salida Y\n",
    "def describe_categories(vector_x, vector_y):\n",
    "    # agrupamos el vector de entrada X de acuerdo al vector de salida Y\n",
    "    grouped = vector_x.groupby(vector_y)\n",
    "    for name, group in grouped:\n",
    "        print(\"\\n\",(\"=\"*50))\n",
    "        print(f'Clase: {name}')\n",
    "        print(\"=\"*50)\n",
    "        # por cada grupo, accedemos a cada una de las columnas\n",
    "        for col in group.columns:\n",
    "            # validamos que el tipo de dato de la columna sea numerico y de ser el caso mosstramos las estadisticas\n",
    "            if group[col].dtype == 'float64' or group[col].dtype == 'int64':\n",
    "                print(f\"=> '{col}':\")\n",
    "                print(f\"\\t-Media: {group[col].mean()}\")\n",
    "                print(f\"\\t-Mediana: {group[col].median()}\")\n",
    "                print(f\"\\t-Desviacion estandar: {group[col].std()}\")\n",
    "                print(f\"\\t-Minimo: {group[col].min()}\")\n",
    "                print(f\"\\t-Maximo: {group[col].max()}\")\n",
    "            else:\n",
    "                print(f\"=> '{col}':\")\n",
    "                print(f\"\\tValores unicos: {group[col].unique()}\")\n",
    "                print(f\"\\tCantidad de valores unicos: {group[col].nunique()}\")            \n",
    "        \n",
    "\n",
    "describe_categories(vector_x, vector_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# PASO 3: LIMPIEZA DE DATASET\n",
    "Sección para limpiar el dataset para eliminar valores que no aportan al modelo, como los valores nulos o NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# juntamos los vectores de entrada y salida en un solo dataframe\n",
    "df = vector_x.join(vector_y)\n",
    "# mostramos la cantidad de registros\n",
    "print(f'Cantidad de registros (Before cleaning): {len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminamos los registros que tengan valores nulos en alguna de las columnas\n",
    "df = df.dropna()\n",
    "# mostramos la cantidad de registros\n",
    "print(f'Cantidad de registros: (After cleaning) {len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de nuevo separamos el dataframe en dos vectores, uno con las variables independientes y otro con la variable dependiente\n",
    "vector_x, vector_y = separate_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conservamos unicamente las columnas con tipo de dato Inter o Continuous\n",
    "vector_x = vector_x.select_dtypes(include=['int64', 'float64'])\n",
    "# mostramos las primeras 5 filas del vector de entrada\n",
    "vector_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Otra forma de limpiar el vector de entrada. Usa el dataset original y los tipos de datos del dataset pero no es tan eficiente como el metodo anterior ya que alginas columnas con tipo de dato numerico no son numericas en el dataset')\n",
    "\"\"\"\n",
    "for col_name in vector_x.columns:\n",
    "    # verificar el tipo de dato de cada columna usando el dataset\n",
    "    if col_name in dataset.variables['name'].values:\n",
    "        # obtener el tipo de dato de la columna en el dataset\n",
    "        col_type = dataset.variables['type'][dataset.variables['name'] == col_name].values[0]\n",
    "        # eliminamos del vector_x aquellas columnas que no son numericas\n",
    "        if col_type != 'Integer' and col_type != 'Continuous':\n",
    "            vector_x = vector_x.drop(col_name, axis=1)\n",
    "        else:        \n",
    "            # parseamos las columnas a tipo de dato float64\n",
    "            vector_x[col_name] = vector_x[col_name].astype('float64')                    \n",
    "\n",
    "# mostramos las primeras 5 filas del vector de entrada\n",
    "vector_x.head()                    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# PASO 4: IMPLEMENTACIÓN DE MODELOS DE ML Y EVALUACIÓN CON DIFERENTES MÉTRICAS\n",
    "Sección para implementar los modelos Minima Distancia y KNN (K=1) para evaluar con los metodos: train-test split, k-fold cross validation y bootstrapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
