{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESCOM - IIA\n",
    "#### FUNDAMENTOS DE INTELIGENCIA ARTIFICIAL - PROYECTO ML\n",
    "#### Semestre 2023-2 - Grupo 4BV2\n",
    "--- \n",
    "##### Autor:\n",
    "- **Valdés Luis Eliot Fabián**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos la librerias necesarias\n",
    "from ucimlrepo import fetch_ucirepo  # libreria de repositorios de datasets\n",
    "import pandas as pd  # libreria para el manejo de dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# PASO 1: Carga de datos\n",
    "Sección inicial para obtener el dataset, describirlo de manera general usando estadisticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos los datasets a utilizar\n",
    "datasets = {\n",
    "    \"Eliot\": 53, # Iris\n",
    "    \"Ethel\": 17, # Breast Cancer\n",
    "    \"Leo\": 878, # Cirrhosis\n",
    "    \"Adair\": 109, # Wine\n",
    "}\n",
    "dataset = fetch_ucirepo(id=datasets[\"Eliot\"]) # cargamos el dataset que deseemos utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostramos un pequeño resumen de lo que trata el dataset \n",
    "dataset.metadata.abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtenemos los datos\n",
    "X = dataset.data.features \n",
    "y = dataset.data.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos un dataframe con los datos\n",
    "df = pd.DataFrame(X, columns=dataset.data.feature_names)\n",
    "# agregamos la columna target\n",
    "df['target'] = y\n",
    "\n",
    "# mostramos la cantidad de registros\n",
    "print(f'Cantidad de registros: {len(df)}')\n",
    "\n",
    "# imprimimos los primeros 5 registros\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostramos los tipos de datos de cada columna\n",
    "print(f\"Tipos de datos (Metodo pandas):\\n{df.dtypes}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostramos los tipos de datos usando los metodos de la librearia de repositorios\n",
    "dataframe_tipos = pd.DataFrame({'Variable Name': dataset.variables['name'], 'Type': dataset.variables['type']})\n",
    "print(f\"Tipos de datos (Metodo ucimlrepo):\\n{dataframe_tipos}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# por cada columna hacer lo siguiente \n",
    "# si el tipo de dato es numerico, mostrar la media, mediana, desviacion estandar, minimo y maximo\n",
    "# si el tipo de dato es categorico, mostrar la cantidad de valores unicos\n",
    "\n",
    "# limitamos la cantidad de columnas a 10\n",
    "for col in df.columns[:10]:\n",
    "    if df[col].dtype == 'float64' or df[col].dtype == 'int64':\n",
    "        print(f\"=> '{col}':\")\n",
    "        print(f\"\\t-Media: {df[col].mean()}\")\n",
    "        print(f\"\\t-Mediana: {df[col].median()}\")\n",
    "        print(f\"\\t-Desviacion estandar: {df[col].std()}\")\n",
    "        print(f\"\\t-Minimo: {df[col].min()}\")\n",
    "        print(f\"\\t-Maximo: {df[col].max()}\")\n",
    "    else:\n",
    "        print(f\"=> '{col}':\")\n",
    "        print(f\"\\t-Valores unicos: {df[col].unique()}\")\n",
    "        print(f\"\\t-Cantidad de valores unicos: {df[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# PASO 2: PREPROCESAMIENTO DE DATOS\n",
    "\n",
    "Sección para preprocesar los datos, aquí separamos el dataset en los vectores de entrada X & de salida Y(las clases que son definidas con tipo de dato categorico)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion para separar cualquier dataframe en dos vectores (entrada y salida)\n",
    "def separate_dataframe(df):\n",
    "    vector_x = df.drop(df.columns[-1], axis=1) # obtencion de variables de entrada\n",
    "    vector_y = df[df.columns[-1]] # obtencion de variable de salida (clase/target)\n",
    "    return vector_x, vector_y\n",
    "\n",
    "# separamos el dataframe en dos vectores, uno con las variables independientes y otro con la variable dependiente\n",
    "vector_x, vector_y = separate_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostramos los primeros 5 registros del vector de entrada X\n",
    "vector_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostramos los primeros 5 registros del vector de salida Y\n",
    "vector_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostramos los valores unicos del vector de salida Y\n",
    "vector_y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos una funcion que recibe como parametros el vector de entrada X y el vector de salida Y\n",
    "def describe_categories(vector_x, vector_y):\n",
    "    # agrupamos el vector de entrada X de acuerdo al vector de salida Y\n",
    "    grouped = vector_x.groupby(vector_y)\n",
    "    for name, group in grouped:\n",
    "        print(\"\\n\",(\"=\"*50))\n",
    "        print(f'Clase: {name}')\n",
    "        print(\"=\"*50)\n",
    "        # por cada grupo, accedemos a cada una de las columnas\n",
    "        for col in group.columns:\n",
    "            # validamos que el tipo de dato de la columna sea numerico y de ser el caso mosstramos las estadisticas\n",
    "            if group[col].dtype == 'float64' or group[col].dtype == 'int64':\n",
    "                print(f\"=> '{col}':\")\n",
    "                print(f\"\\t-Media: {group[col].mean()}\")\n",
    "                print(f\"\\t-Mediana: {group[col].median()}\")\n",
    "                print(f\"\\t-Desviacion estandar: {group[col].std()}\")\n",
    "                print(f\"\\t-Minimo: {group[col].min()}\")\n",
    "                print(f\"\\t-Maximo: {group[col].max()}\")\n",
    "            else:\n",
    "                print(f\"=> '{col}':\")\n",
    "                print(f\"\\tValores unicos: {group[col].unique()}\")\n",
    "                print(f\"\\tCantidad de valores unicos: {group[col].nunique()}\")            \n",
    "        \n",
    "\n",
    "describe_categories(vector_x, vector_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# PASO 3: LIMPIEZA DE DATASET\n",
    "Sección para limpiar el dataset para eliminar valores que no aportan al modelo, como los valores nulos o NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# juntamos los vectores de entrada y salida en un solo dataframe\n",
    "df = vector_x.join(vector_y)\n",
    "# mostramos la cantidad de registros\n",
    "print(f'Cantidad de registros (Before cleaning): {len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminamos los registros que tengan valores nulos en alguna de las columnas\n",
    "df = df.dropna()\n",
    "# mostramos la cantidad de registros\n",
    "print(f'Cantidad de registros: (After cleaning) {len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de nuevo separamos el dataframe en dos vectores, uno con las variables independientes y otro con la variable dependiente\n",
    "vector_x, vector_y = separate_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conservamos unicamente las columnas con tipo de dato Inter o Continuous\n",
    "vector_x = vector_x.select_dtypes(include=['int64', 'float64'])\n",
    "# mostramos las primeras 5 filas del vector de entrada\n",
    "vector_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Otra forma de limpiar el vector de entrada. Usa el dataset original y los tipos de datos del dataset pero no es tan eficiente como el metodo anterior ya que alginas columnas con tipo de dato numerico no son numericas en el dataset')\n",
    "\"\"\"\n",
    "for col_name in vector_x.columns:\n",
    "    # verificar el tipo de dato de cada columna usando el dataset\n",
    "    if col_name in dataset.variables['name'].values:\n",
    "        # obtener el tipo de dato de la columna en el dataset\n",
    "        col_type = dataset.variables['type'][dataset.variables['name'] == col_name].values[0]\n",
    "        # eliminamos del vector_x aquellas columnas que no son numericas\n",
    "        if col_type != 'Integer' and col_type != 'Continuous':\n",
    "            vector_x = vector_x.drop(col_name, axis=1)\n",
    "        else:        \n",
    "            # parseamos las columnas a tipo de dato float64\n",
    "            vector_x[col_name] = vector_x[col_name].astype('float64')                    \n",
    "\n",
    "# mostramos las primeras 5 filas del vector de entrada\n",
    "vector_x.head()                    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# PASO 4: IMPLEMENTACIÓN DE MODELOS DE ML Y EVALUACIÓN CON DIFERENTES MÉTRICAS\n",
    "Sección para implementar los modelos Minima Distancia y KNN (K=1) para evaluar con los metodos: train-test split, k-fold cross validation y bootstrapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - DESARROLLO DE MODELO MINIMA DISTANCIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esta función calcula los centroides de diferentes clases dadas en un conjunto de datos.\n",
    "def calcular_centroides(X, y):\n",
    "    # X es una lista de vectores (puntos en un espacio n-dimensional).\n",
    "    # y es una lista de etiquetas de clase correspondientes a cada vector en X.\n",
    "\n",
    "    clases = set(y)  # Obtiene un conjunto único de clases en y.\n",
    "\n",
    "    # Inicializa un diccionario para almacenar la suma de vectores de cada clase.\n",
    "    # Cada clase c tiene un vector de longitud len(X[0]) (la dimensión de los vectores en X).\n",
    "    centroides = {c: [0] * len(X[0]) for c in clases}\n",
    "\n",
    "    # Inicializa un diccionario para contar el número de vectores en cada clase.\n",
    "    contador = {c: 0 for c in clases}\n",
    "\n",
    "    # Itera sobre los pares de vectores y etiquetas.\n",
    "    for xi, yi in zip(X, y):\n",
    "        contador[yi] += 1  # Incrementa el contador para la clase yi.\n",
    "        for i in range(len(xi)):\n",
    "            centroides[yi][i] += xi[i]  # Suma cada componente del vector xi al vector del centroide de su clase.\n",
    "\n",
    "    # Divide cada componente del vector de centroide por el número de vectores en esa clase\n",
    "    # para obtener el promedio, que es el centroide.\n",
    "    for c in centroides:\n",
    "        centroides[c] = [x / contador[c] for x in centroides[c]]\n",
    "    \n",
    "    return centroides  # Retorna el diccionario de centroides.\n",
    "        \n",
    "# Esta función clasifica nuevos vectores en X basándose en el centroide más cercano de las clases precalculadas.        \n",
    "def clasificador_minima_distancia(X, centroides):\n",
    "    # X es una lista de vectores a clasificar.\n",
    "    # centroides es un diccionario de centroides precalculados para cada clase.\n",
    "\n",
    "    predicciones = []  # Lista para almacenar las predicciones.\n",
    "\n",
    "    # Itera sobre cada vector en X.\n",
    "    for xi in X:\n",
    "        # Calcula la distancia al cuadrado de xi a cada centroide.\n",
    "        distancias = {c: sum((xi[j] - centroides[c][j])**2 for j in range(len(xi))) for c in centroides}\n",
    "\n",
    "        # Encuentra la clase con la distancia mínima y la agrega a las predicciones.\n",
    "        predicciones.append(min(distancias, key=distancias.get))\n",
    "    \n",
    "    return predicciones  # Retorna la lista de clases predichas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DESARROLLO DE MODELO K NEAREST NEIGHBORS (K=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificador_knn(X_train, y_train, X_test):\n",
    "    # Lista para almacenar las predicciones de las clases para cada punto en X_test\n",
    "    predicciones = []\n",
    "\n",
    "    # Itera sobre cada punto de prueba en X_test\n",
    "    for xi in X_test:\n",
    "        # Calcula la distancia euclidiana cuadrada entre el punto de prueba xi \n",
    "        # y todos los puntos en el conjunto de entrenamiento X_train\n",
    "        distancias = [sum((xi[j] - X_train[i][j])**2 for j in range(len(xi))) \n",
    "                      for i in range(len(X_train))]\n",
    "\n",
    "        # Encuentra el índice del punto más cercano (menor distancia) en X_train\n",
    "        min_index = distancias.index(min(distancias))\n",
    "\n",
    "        # Agrega la etiqueta de clase correspondiente al punto más cercano a las predicciones\n",
    "        predicciones.append(y_train[min_index])\n",
    "\n",
    "    # Devuelve la lista de predicciones para cada punto en X_test\n",
    "    return predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MÉTODOS DE VALIDACIÓN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - DESARROLLO DE MÉTODO TEST-TRAIN SPLIT (80-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenamiento_prueba(X, y, porcentaje_prueba):\n",
    "    # Calcula el índice de corte para dividir los datos en entrenamiento y prueba segun el porcentaje de prueba\n",
    "    indice_corte = int(len(X) * (1 - porcentaje_prueba))\n",
    "\n",
    "    # Divide el conjunto de datos X en dos partes: \n",
    "    # X_train contiene los datos desde el inicio hasta el índice de corte.\n",
    "    # Esto forma el conjunto de entrenamiento.\n",
    "    X_train = X[:indice_corte]\n",
    "\n",
    "    # y_train contiene las etiquetas correspondientes a X_train.\n",
    "    y_train = y[:indice_corte]\n",
    "\n",
    "    # X_test contiene los datos desde el índice de corte hasta el final.\n",
    "    # Esto forma el conjunto de prueba.\n",
    "    X_test = X[indice_corte:]\n",
    "\n",
    "    # y_test contiene las etiquetas correspondientes a X_test.\n",
    "    y_test = y[indice_corte:]\n",
    "\n",
    "    # La función devuelve los conjuntos de entrenamiento y prueba.\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - DESARROLLO DE MÉTODO K-FOLD CROSS VALIDATION (K=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(X, y, k):\n",
    "    # Calcular el tamaño de cada fold dividiendo el tamaño total del conjunto de datos por k.\n",
    "    tamaño_fold = len(X) // k\n",
    "\n",
    "    # Iterar k veces para crear k folds diferentes.\n",
    "    for i in range(k):\n",
    "        # Calcular los índices de inicio y fin para el conjunto de prueba.\n",
    "        # el inicio va desde 0 hasta el tamaño del fold multiplicado por el numero de iteracion\n",
    "        inicio = i * tamaño_fold\n",
    "        # el fin va desde el inicio mas el tamaño del fold hasta el tamaño del fold multiplicado por el numero de iteracion mas 1\n",
    "        fin = (i + 1) * tamaño_fold if i != k - 1 else len(X)\n",
    "\n",
    "        # Crear el conjunto de entrenamiento excluyendo los datos del conjunto de prueba actual.\n",
    "        X_train = X[:inicio] + X[fin:]\n",
    "        y_train = y[:inicio] + y[fin:]\n",
    "\n",
    "        # Crear el conjunto de prueba para la iteración actual.\n",
    "        X_test = X[inicio:fin]\n",
    "        y_test = y[inicio:fin]\n",
    "\n",
    "        # 'yield' devuelve un generador que produce una serie de conjuntos de entrenamiento y prueba.\n",
    "        yield X_train, y_train, X_test, y_test\n",
    "\"\"\"\n",
    "OJO: Un generador es un tipo especial de iterador, que a diferencia de una lista o cualquier colección que almacena todos sus elementos en la memoria, produce elementos uno a la vez y solo cuando se solicitan.\n",
    "Manejo de Memoria Eficiente: Los generadores calculan los valores sobre la marcha y los devuelven uno a la vez, lo que ahorra memoria, especialmente útil para procesar grandes cantidades de datos.\n",
    "Estado de Función Suspendido: Cuando se encuentra un yield, el estado de la función se \"congela\", y todas las variables y su estado se mantienen hasta la próxima vez que el generador es llamado.\n",
    "Iteración Conveniente: Al usar un generador, no es necesario esperar a que todos los elementos estén disponibles. Se puede comenzar a procesar el primer elemento tan pronto como esté disponible.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - DESARROLLO DE MÉTODO BOOTSTRAPPING (B=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def bootstrap(X, y, n):\n",
    "    # Este bucle se ejecuta 'n' veces. En cada iteración, se realiza un proceso de remuestreo.\n",
    "    for _ in range(n):\n",
    "        # Se generan índices aleatorios para el conjunto de entrenamiento.\n",
    "        # La longitud de la lista de índices es igual a la longitud de 'X'.\n",
    "        # 'random.randint(0, len(X) - 1)' genera un índice aleatorio entre 0 y len(X)-1.\n",
    "        indices = [random.randint(0, len(X) - 1) for _ in range(len(X))]\n",
    "\n",
    "        # Se crean los conjuntos de entrenamiento.\n",
    "        # 'X_train' contiene elementos de 'X' en las posiciones indicadas por 'indices'.\n",
    "        # 'y_train' contiene elementos de 'y' en las mismas posiciones.\n",
    "        X_train = [X[i] for i in indices]\n",
    "        y_train = [y[i] for i in indices]\n",
    "\n",
    "        # Se crean los conjuntos de prueba.\n",
    "        # 'X_test' y 'y_test' contienen elementos de 'X' y 'y' que no están en los índices de entrenamiento.\n",
    "        X_test = [X[i] for i in range(len(X)) if i not in indices]\n",
    "        y_test = [y[i] for i in range(len(X)) if i not in indices]\n",
    "\n",
    "        # La función 'yield' devuelve los conjuntos de entrenamiento y prueba.\n",
    "        # En cada iteración del bucle, se devuelve un nuevo conjunto de remuestreo.\n",
    "        yield X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCIONES AUXILIARES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - FUNCION PARA CALCULAR LA RELACIÓN EFIENCIA-ERROR DE UN MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_eficiencia_error(y_real, y_pred):\n",
    "    # Se inicializa un contador para los valores correctos\n",
    "    correctos = sum(1 for real, pred in zip(y_real, y_pred) if real == pred)\n",
    "    # La eficiencia se calcula como la proporción de predicciones correctas\n",
    "    eficiencia = correctos / len(y_real)\n",
    "    # El error se calcula como el complemento de la eficiencia\n",
    "    error = 1 - eficiencia\n",
    "    # La función devuelve tanto la eficiencia como el error\n",
    "    return eficiencia, error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - FUNCION PARA TRANSFORMAR UN DATAFRAME EN UNA LISTA DE LISTAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformar_datos(vector_x, vector_y):\n",
    "    # Convierte el vector_x en una lista. \n",
    "    # Supone que vector_x es una estructura de datos como un DataFrame de pandas,\n",
    "    # y utiliza el método .values.tolist() para convertirlo en una lista de Python.\n",
    "    X = vector_x.values.tolist() \n",
    "\n",
    "    # Realiza la misma conversión para vector_y, transformándolo en una lista.\n",
    "    y = vector_y.values.tolist()\n",
    "\n",
    "    # Comprueba si el primer elemento de y es una lista.\n",
    "    # Si es así, se asume que y es una lista de listas, y se procede a \"aplanar\" esta lista.\n",
    "    # Esto se hace mediante una comprensión de lista que toma el primer elemento de cada sublista.\n",
    "    # Por ejemplo, si y = [[1], [2], [3]], esto se convierte en [1, 2, 3].\n",
    "    # Si y no es una lista de listas, se mantiene como está.\n",
    "    y = [item[0] for item in y] if isinstance(y[0], list) else y\n",
    "\n",
    "    # Devuelve las listas X y y transformadas.\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### 4 => CONTENEDOR DE EJECUCIÓN DE MODELO: DISTANCIA MINIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_min_distance_model(X, y):\n",
    "    # ENTRENAMIENTO Y PRUEBA\n",
    "    X_train, y_train, X_test, y_test = entrenamiento_prueba(X, y, porcentaje_prueba=0.2)\n",
    "    # Calcular centroides y hacer predicciones\n",
    "    centroides = calcular_centroides(X_train, y_train)\n",
    "    predicciones = clasificador_minima_distancia(X_test, centroides)\n",
    "    # Calcular eficiencia y error\n",
    "    eficiencia, error = calcular_eficiencia_error(y_test, predicciones)\n",
    "    print(f\"Minima distancia: eficiencia = {eficiencia}, error = {error} - Metodo de entrenamiento y prueba\")\n",
    "    \n",
    "    # K-FOLD CROSS VALIDATION\n",
    "    eficiencias = []\n",
    "    errores = []\n",
    "    k = 5  # Número de folds\n",
    "    for X_train, y_train, X_test, y_test in k_fold_cross_validation(X, y, k):\n",
    "        centroides = calcular_centroides(X_train, y_train)\n",
    "        predicciones = clasificador_minima_distancia(X_test, centroides)\n",
    "        eficiencia, error = calcular_eficiencia_error(y_test, predicciones)\n",
    "        eficiencias.append(eficiencia)\n",
    "        errores.append(error)\n",
    "    # Calcular promedios\n",
    "    eficiencia_promedio = sum(eficiencias) / k\n",
    "    error_promedio = sum(errores) / k\n",
    "    print(f\"Minima distancia: eficiencia = {eficiencia_promedio}, error = {error_promedio} - K-fold cross validation\")\n",
    "    \n",
    "    # BOOTSTRAP\n",
    "    eficiencias = []\n",
    "    errores = []\n",
    "    n_iteraciones = 100  # Número de iteraciones de Bootstrap\n",
    "    for X_train, y_train, X_test, y_test in bootstrap(X, y, n_iteraciones):\n",
    "        centroides = calcular_centroides(X_train, y_train)\n",
    "        predicciones = clasificador_minima_distancia(X_test, centroides)\n",
    "        eficiencia, error = calcular_eficiencia_error(y_test, predicciones)\n",
    "        eficiencias.append(eficiencia)\n",
    "        errores.append(error)\n",
    "    # Calcular promedios\n",
    "    eficiencia_promedio = sum(eficiencias) / n_iteraciones\n",
    "    error_promedio = sum(errores) / n_iteraciones\n",
    "    print(f\"Minima distancia: eficiencia = {eficiencia_promedio}, error = {error_promedio} - Bootstrap\")      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### 5 => CONTENDOR DE EJECUCIÓN DE MODELO: KNN(K=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_knn_model(X, y):\n",
    "    # ENTRENAMIENTO Y PRUEBA\n",
    "    # Dividir los datos\n",
    "    X_train, y_train, X_test, y_test = entrenamiento_prueba(X, y, porcentaje_prueba=0.2)\n",
    "    # Hacer predicciones\n",
    "    predicciones = clasificador_knn(X_train, y_train, X_test)\n",
    "    # Calcular eficiencia y error\n",
    "    eficiencia, error = calcular_eficiencia_error(y_test, predicciones)\n",
    "    print(f\"KNN: eficiencia = {eficiencia}, error = {error} - Metodo de entrenamiento y prueba\")\n",
    "    \n",
    "    # K-FOLD CROSS VALIDATION\n",
    "    eficiencias = []\n",
    "    errores = []\n",
    "    k = 5  # Número de folds\n",
    "    for X_train, y_train, X_test, y_test in k_fold_cross_validation(X, y, k):\n",
    "        predicciones = clasificador_knn(X_train, y_train, X_test)\n",
    "        eficiencia, error = calcular_eficiencia_error(y_test, predicciones)\n",
    "        eficiencias.append(eficiencia)\n",
    "        errores.append(error)\n",
    "    # Calcular promedios\n",
    "    eficiencia_promedio = sum(eficiencias) / k\n",
    "    error_promedio = sum(errores) / k\n",
    "    print(f\"KNN: eficiencia = {eficiencia_promedio}, error = {error_promedio} - K-fold cross validation\")\n",
    "    \n",
    "    # BOOTSTRAP\n",
    "    eficiencias = []\n",
    "    errores = []\n",
    "    n_iteraciones = 10  # Número de iteraciones de Bootstrap\n",
    "    for X_train, y_train, X_test, y_test in bootstrap(X, y, n_iteraciones):\n",
    "        predicciones = clasificador_knn(X_train, y_train, X_test)\n",
    "        eficiencia, error = calcular_eficiencia_error(y_test, predicciones)\n",
    "        eficiencias.append(eficiencia)\n",
    "        errores.append(error)\n",
    "    # Calcular promedios\n",
    "    eficiencia_promedio = sum(eficiencias) / n_iteraciones\n",
    "    error_promedio = sum(errores) / n_iteraciones\n",
    "    print(f\"KNN: eficiencia = {eficiencia_promedio}, error = {error_promedio} - Bootstrap\")       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EJECUCIÓN DE MODELOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformamos los vectores de entrada y salida a listas\n",
    "X, y = transformar_datos(vector_x, vector_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# PASO 4: EJECUCIÓN DE DISTANCIA MINIMA\n",
    "- #### 4.A => DISTANCIA MINIMA - EVALUADO CON: TRAIN-TEST SPLIT\n",
    "- #### 4.B => DISTANCIA MINIMA - EVALUADO CON: K FOLD CROSS VALIDATION\n",
    "- #### 4.C => DISTANCIA MINIMA - EVALUADO CON: BOOTSTRAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejecutamos el modelo de distancia minima y validamos internamente con cada metodo\n",
    "run_min_distance_model(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# PASO 5: EJECUCIÓN DE KNN(K=1)\n",
    "- #### 5.A => KNN - EVALUADO CON: TRAIN-TEST SPLIT\n",
    "- #### 5.B => KNN - EVALUADO CON: K FOLD CROSS VALIDATION\n",
    "- #### 5.C => KNN - EVALUADO CON: BOOTSTRAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejecutamos el modelo de KNN y validamos internamente con cada metodo\n",
    "run_knn_model(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# PASO 6: ELIMINACIÓN DE ATRIBUTOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seleccionamos el atributo 1 (columna) de mi vector_x de entradas\n",
    "atributo_1 = vector_x.columns[1]\n",
    "# seleccionamos el atributo 2 (columna) de mi vector_x de entradas\n",
    "atributo_2 = vector_x.columns[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminamos el atributo_1 pero de un vector de entradas de prueba\n",
    "vector_x_prueba_1 = vector_x.drop(atributo_1, axis=1)\n",
    "\n",
    "# repetimos proceso para hacer test de modelo\n",
    "X, y = transformar_datos(vector_x_prueba_1, vector_y)\n",
    "run_min_distance_model(X, y)\n",
    "run_knn_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminamos el atributo_2 de mi vector de entradas pero de un vector de entradas de prueba 2\n",
    "vector_x_prueba_2 = vector_x.drop(atributo_2, axis=1)\n",
    "\n",
    "# repetimos proceso para hacer test de modelo\n",
    "X, y = transformar_datos(vector_x_prueba_2, vector_y)\n",
    "run_min_distance_model(X, y)\n",
    "run_knn_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminamos los atributos 1 y 2 de mi vector de entradas pero de un vector de entradas de prueba 3\n",
    "vector_x_prueba_3 = vector_x.drop([atributo_1, atributo_2], axis=1)\n",
    "\n",
    "# repetimos proceso para hacer test de modelo\n",
    "X, y = transformar_datos(vector_x_prueba_3, vector_y)\n",
    "run_min_distance_model(X, y)\n",
    "run_knn_model(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
