{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESCOM - IIA\n",
    "#### FUNDAMENTOS DE INTELIGENCIA ARTIFICIAL - PROYECTO ML\n",
    "#### Semestre 2023-2 - Grupo 4BV2\n",
    "--- \n",
    "##### Autor:\n",
    "- **Valdés Luis Eliot Fabián**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos la librerias necesarias\n",
    "from ucimlrepo import fetch_ucirepo  # libreria de repositorios de datasets\n",
    "import pandas as pd  # libreria para el manejo de dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# PASO 1: Carga de datos\n",
    "Sección inicial para obtener el dataset, describirlo de manera general usando estadisticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos los datasets a utilizar\n",
    "datasets = {\n",
    "    \"Eliot\": 53, # Iris\n",
    "    \"Ethel\": 17, # Breast Cancer\n",
    "    \"Leo\": 878, # Cirrhosis\n",
    "    \"Adair\": 19, # Wine\n",
    "}\n",
    "dataset = fetch_ucirepo(id=datasets[\"Adair\"]) # cargamos el dataset que deseemos utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Derived from simple hierarchical decision model, this database may be useful for testing constructive induction and structure discovery methods.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mostramos un pequeño resumen de lo que trata el dataset \n",
    "dataset.metadata.abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtenemos los datos\n",
    "X = dataset.data.features \n",
    "y = dataset.data.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros: 1728\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety target\n",
       "0  vhigh  vhigh     2       2    small    low  unacc\n",
       "1  vhigh  vhigh     2       2    small    med  unacc\n",
       "2  vhigh  vhigh     2       2    small   high  unacc\n",
       "3  vhigh  vhigh     2       2      med    low  unacc\n",
       "4  vhigh  vhigh     2       2      med    med  unacc"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creamos un dataframe con los datos\n",
    "df = pd.DataFrame(X, columns=dataset.data.feature_names)\n",
    "# agregamos la columna target\n",
    "df['target'] = y\n",
    "\n",
    "# mostramos la cantidad de registros\n",
    "print(f'Cantidad de registros: {len(df)}')\n",
    "\n",
    "# imprimimos los primeros 5 registros\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos de datos (Metodo pandas):\n",
      "buying      object\n",
      "maint       object\n",
      "doors       object\n",
      "persons     object\n",
      "lug_boot    object\n",
      "safety      object\n",
      "target      object\n",
      "dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mostramos los tipos de datos de cada columna\n",
    "print(f\"Tipos de datos (Metodo pandas):\\n{df.dtypes}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos de datos (Metodo ucimlrepo):\n",
      "  Variable Name         Type\n",
      "0        buying  Categorical\n",
      "1         maint  Categorical\n",
      "2         doors  Categorical\n",
      "3       persons  Categorical\n",
      "4      lug_boot  Categorical\n",
      "5        safety  Categorical\n",
      "6         class  Categorical\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mostramos los tipos de datos usando los metodos de la librearia de repositorios\n",
    "dataframe_tipos = pd.DataFrame({'Variable Name': dataset.variables['name'], 'Type': dataset.variables['type']})\n",
    "print(f\"Tipos de datos (Metodo ucimlrepo):\\n{dataframe_tipos}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> 'buying':\n",
      "\t-Valores unicos: ['vhigh' 'high' 'med' 'low']\n",
      "\t-Cantidad de valores unicos: 4\n",
      "=> 'maint':\n",
      "\t-Valores unicos: ['vhigh' 'high' 'med' 'low']\n",
      "\t-Cantidad de valores unicos: 4\n",
      "=> 'doors':\n",
      "\t-Valores unicos: ['2' '3' '4' '5more']\n",
      "\t-Cantidad de valores unicos: 4\n",
      "=> 'persons':\n",
      "\t-Valores unicos: ['2' '4' 'more']\n",
      "\t-Cantidad de valores unicos: 3\n",
      "=> 'lug_boot':\n",
      "\t-Valores unicos: ['small' 'med' 'big']\n",
      "\t-Cantidad de valores unicos: 3\n",
      "=> 'safety':\n",
      "\t-Valores unicos: ['low' 'med' 'high']\n",
      "\t-Cantidad de valores unicos: 3\n",
      "=> 'target':\n",
      "\t-Valores unicos: ['unacc' 'acc' 'vgood' 'good']\n",
      "\t-Cantidad de valores unicos: 4\n"
     ]
    }
   ],
   "source": [
    "# por cada columna hacer lo siguiente \n",
    "# si el tipo de dato es numerico, mostrar la media, mediana, desviacion estandar, minimo y maximo\n",
    "# si el tipo de dato es categorico, mostrar la cantidad de valores unicos\n",
    "\n",
    "# limitamos la cantidad de columnas a 10\n",
    "for col in df.columns[:10]:\n",
    "    if df[col].dtype == 'float64' or df[col].dtype == 'int64':\n",
    "        print(f\"=> '{col}':\")\n",
    "        print(f\"\\t-Media: {df[col].mean()}\")\n",
    "        print(f\"\\t-Mediana: {df[col].median()}\")\n",
    "        print(f\"\\t-Desviacion estandar: {df[col].std()}\")\n",
    "        print(f\"\\t-Minimo: {df[col].min()}\")\n",
    "        print(f\"\\t-Maximo: {df[col].max()}\")\n",
    "    else:\n",
    "        print(f\"=> '{col}':\")\n",
    "        print(f\"\\t-Valores unicos: {df[col].unique()}\")\n",
    "        print(f\"\\t-Cantidad de valores unicos: {df[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# PASO 2: PREPROCESAMIENTO DE DATOS\n",
    "\n",
    "Sección para preprocesar los datos, aquí separamos el dataset en los vectores de entrada X & de salida Y(las clases que son definidas con tipo de dato categorico)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion para separar cualquier dataframe en dos vectores (entrada y salida)\n",
    "def separate_dataframe(df):\n",
    "    vector_x = df.drop(df.columns[-1], axis=1) # obtencion de variables de entrada\n",
    "    vector_y = df[df.columns[-1]] # obtencion de variable de salida (clase/target)\n",
    "    return vector_x, vector_y\n",
    "\n",
    "# separamos el dataframe en dos vectores, uno con las variables independientes y otro con la variable dependiente\n",
    "vector_x, vector_y = separate_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety\n",
       "0  vhigh  vhigh     2       2    small    low\n",
       "1  vhigh  vhigh     2       2    small    med\n",
       "2  vhigh  vhigh     2       2    small   high\n",
       "3  vhigh  vhigh     2       2      med    low\n",
       "4  vhigh  vhigh     2       2      med    med"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mostramos los primeros 5 registros del vector de entrada X\n",
    "vector_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    unacc\n",
       "1    unacc\n",
       "2    unacc\n",
       "3    unacc\n",
       "4    unacc\n",
       "Name: target, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mostramos los primeros 5 registros del vector de salida Y\n",
    "vector_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unacc', 'acc', 'vgood', 'good'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mostramos los valores unicos del vector de salida Y\n",
    "vector_y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ==================================================\n",
      "Clase: acc\n",
      "==================================================\n",
      "=> 'buying':\n",
      "\tValores unicos: ['vhigh' 'high' 'med' 'low']\n",
      "\tCantidad de valores unicos: 4\n",
      "=> 'maint':\n",
      "\tValores unicos: ['med' 'low' 'high' 'vhigh']\n",
      "\tCantidad de valores unicos: 4\n",
      "=> 'doors':\n",
      "\tValores unicos: ['2' '3' '4' '5more']\n",
      "\tCantidad de valores unicos: 4\n",
      "=> 'persons':\n",
      "\tValores unicos: ['4' 'more']\n",
      "\tCantidad de valores unicos: 2\n",
      "=> 'lug_boot':\n",
      "\tValores unicos: ['small' 'med' 'big']\n",
      "\tCantidad de valores unicos: 3\n",
      "=> 'safety':\n",
      "\tValores unicos: ['high' 'med']\n",
      "\tCantidad de valores unicos: 2\n",
      "\n",
      " ==================================================\n",
      "Clase: good\n",
      "==================================================\n",
      "=> 'buying':\n",
      "\tValores unicos: ['med' 'low']\n",
      "\tCantidad de valores unicos: 2\n",
      "=> 'maint':\n",
      "\tValores unicos: ['low' 'med']\n",
      "\tCantidad de valores unicos: 2\n",
      "=> 'doors':\n",
      "\tValores unicos: ['2' '3' '4' '5more']\n",
      "\tCantidad de valores unicos: 4\n",
      "=> 'persons':\n",
      "\tValores unicos: ['4' 'more']\n",
      "\tCantidad de valores unicos: 2\n",
      "=> 'lug_boot':\n",
      "\tValores unicos: ['small' 'med' 'big']\n",
      "\tCantidad de valores unicos: 3\n",
      "=> 'safety':\n",
      "\tValores unicos: ['high' 'med']\n",
      "\tCantidad de valores unicos: 2\n",
      "\n",
      " ==================================================\n",
      "Clase: unacc\n",
      "==================================================\n",
      "=> 'buying':\n",
      "\tValores unicos: ['vhigh' 'high' 'med' 'low']\n",
      "\tCantidad de valores unicos: 4\n",
      "=> 'maint':\n",
      "\tValores unicos: ['vhigh' 'high' 'med' 'low']\n",
      "\tCantidad de valores unicos: 4\n",
      "=> 'doors':\n",
      "\tValores unicos: ['2' '3' '4' '5more']\n",
      "\tCantidad de valores unicos: 4\n",
      "=> 'persons':\n",
      "\tValores unicos: ['2' '4' 'more']\n",
      "\tCantidad de valores unicos: 3\n",
      "=> 'lug_boot':\n",
      "\tValores unicos: ['small' 'med' 'big']\n",
      "\tCantidad de valores unicos: 3\n",
      "=> 'safety':\n",
      "\tValores unicos: ['low' 'med' 'high']\n",
      "\tCantidad de valores unicos: 3\n",
      "\n",
      " ==================================================\n",
      "Clase: vgood\n",
      "==================================================\n",
      "=> 'buying':\n",
      "\tValores unicos: ['med' 'low']\n",
      "\tCantidad de valores unicos: 2\n",
      "=> 'maint':\n",
      "\tValores unicos: ['med' 'low' 'high']\n",
      "\tCantidad de valores unicos: 3\n",
      "=> 'doors':\n",
      "\tValores unicos: ['2' '3' '4' '5more']\n",
      "\tCantidad de valores unicos: 4\n",
      "=> 'persons':\n",
      "\tValores unicos: ['4' 'more']\n",
      "\tCantidad de valores unicos: 2\n",
      "=> 'lug_boot':\n",
      "\tValores unicos: ['big' 'med']\n",
      "\tCantidad de valores unicos: 2\n",
      "=> 'safety':\n",
      "\tValores unicos: ['high']\n",
      "\tCantidad de valores unicos: 1\n"
     ]
    }
   ],
   "source": [
    "# creamos una funcion que recibe como parametros el vector de entrada X y el vector de salida Y\n",
    "def describe_categories(vector_x, vector_y):\n",
    "    # agrupamos el vector de entrada X de acuerdo al vector de salida Y\n",
    "    grouped = vector_x.groupby(vector_y)\n",
    "    for name, group in grouped:\n",
    "        print(\"\\n\",(\"=\"*50))\n",
    "        print(f'Clase: {name}')\n",
    "        print(\"=\"*50)\n",
    "        # por cada grupo, accedemos a cada una de las columnas\n",
    "        for col in group.columns:\n",
    "            # validamos que el tipo de dato de la columna sea numerico y de ser el caso mosstramos las estadisticas\n",
    "            if group[col].dtype == 'float64' or group[col].dtype == 'int64':\n",
    "                print(f\"=> '{col}':\")\n",
    "                print(f\"\\t-Media: {group[col].mean()}\")\n",
    "                print(f\"\\t-Mediana: {group[col].median()}\")\n",
    "                print(f\"\\t-Desviacion estandar: {group[col].std()}\")\n",
    "                print(f\"\\t-Minimo: {group[col].min()}\")\n",
    "                print(f\"\\t-Maximo: {group[col].max()}\")\n",
    "            else:\n",
    "                print(f\"=> '{col}':\")\n",
    "                print(f\"\\tValores unicos: {group[col].unique()}\")\n",
    "                print(f\"\\tCantidad de valores unicos: {group[col].nunique()}\")            \n",
    "        \n",
    "\n",
    "describe_categories(vector_x, vector_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# PASO 3: LIMPIEZA DE DATASET\n",
    "Sección para limpiar el dataset para eliminar valores que no aportan al modelo, como los valores nulos o NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros (Before cleaning): 1728\n"
     ]
    }
   ],
   "source": [
    "# juntamos los vectores de entrada y salida en un solo dataframe\n",
    "df = vector_x.join(vector_y)\n",
    "# mostramos la cantidad de registros\n",
    "print(f'Cantidad de registros (Before cleaning): {len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros: (After cleaning) 1728\n"
     ]
    }
   ],
   "source": [
    "# eliminamos los registros que tengan valores nulos en alguna de las columnas\n",
    "df = df.dropna()\n",
    "# mostramos la cantidad de registros\n",
    "print(f'Cantidad de registros: (After cleaning) {len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de nuevo separamos el dataframe en dos vectores, uno con las variables independientes y otro con la variable dependiente\n",
    "vector_x, vector_y = separate_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conservamos unicamente las columnas con tipo de dato Inter o Continuous\n",
    "vector_x = vector_x.select_dtypes(include=['int64', 'float64'])\n",
    "# mostramos las primeras 5 filas del vector de entrada\n",
    "vector_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Otra forma de limpiar el vector de entrada. Usa el dataset original y los tipos de datos del dataset pero no es tan eficiente como el metodo anterior ya que alginas columnas con tipo de dato numerico no son numericas en el dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfor col_name in vector_x.columns:\\n    # verificar el tipo de dato de cada columna usando el dataset\\n    if col_name in dataset.variables['name'].values:\\n        # obtener el tipo de dato de la columna en el dataset\\n        col_type = dataset.variables['type'][dataset.variables['name'] == col_name].values[0]\\n        # eliminamos del vector_x aquellas columnas que no son numericas\\n        if col_type != 'Integer' and col_type != 'Continuous':\\n            vector_x = vector_x.drop(col_name, axis=1)\\n        else:        \\n            # parseamos las columnas a tipo de dato float64\\n            vector_x[col_name] = vector_x[col_name].astype('float64')                    \\n\\n# mostramos las primeras 5 filas del vector de entrada\\nvector_x.head()                    \\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Otra forma de limpiar el vector de entrada. Usa el dataset original y los tipos de datos del dataset pero no es tan eficiente como el metodo anterior ya que alginas columnas con tipo de dato numerico no son numericas en el dataset')\n",
    "\"\"\"\n",
    "for col_name in vector_x.columns:\n",
    "    # verificar el tipo de dato de cada columna usando el dataset\n",
    "    if col_name in dataset.variables['name'].values:\n",
    "        # obtener el tipo de dato de la columna en el dataset\n",
    "        col_type = dataset.variables['type'][dataset.variables['name'] == col_name].values[0]\n",
    "        # eliminamos del vector_x aquellas columnas que no son numericas\n",
    "        if col_type != 'Integer' and col_type != 'Continuous':\n",
    "            vector_x = vector_x.drop(col_name, axis=1)\n",
    "        else:        \n",
    "            # parseamos las columnas a tipo de dato float64\n",
    "            vector_x[col_name] = vector_x[col_name].astype('float64')                    \n",
    "\n",
    "# mostramos las primeras 5 filas del vector de entrada\n",
    "vector_x.head()                    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# PASO 4: IMPLEMENTACIÓN DE MODELOS DE ML Y EVALUACIÓN CON DIFERENTES MÉTRICAS\n",
    "Sección para implementar los modelos Minima Distancia y KNN (K=1) para evaluar con los metodos: train-test split, k-fold cross validation y bootstrapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - DESARROLLO DE MODELO MINIMA DISTANCIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esta función calcula los centroides de diferentes clases dadas en un conjunto de datos.\n",
    "def calcular_centroides(X, y):\n",
    "    # X es una lista de vectores (puntos en un espacio n-dimensional).\n",
    "    # y es una lista de etiquetas de clase correspondientes a cada vector en X.\n",
    "\n",
    "    clases = set(y)  # Obtiene un conjunto único de clases en y.\n",
    "\n",
    "    # Inicializa un diccionario para almacenar la suma de vectores de cada clase.\n",
    "    # Cada clase c tiene un vector de longitud len(X[0]) (la dimensión de los vectores en X).\n",
    "    centroides = {c: [0] * len(X[0]) for c in clases}\n",
    "\n",
    "    # Inicializa un diccionario para contar el número de vectores en cada clase.\n",
    "    contador = {c: 0 for c in clases}\n",
    "\n",
    "    # Itera sobre los pares de vectores y etiquetas.\n",
    "    for xi, yi in zip(X, y):\n",
    "        contador[yi] += 1  # Incrementa el contador para la clase yi.\n",
    "        for i in range(len(xi)):\n",
    "            centroides[yi][i] += xi[i]  # Suma cada componente del vector xi al vector del centroide de su clase.\n",
    "\n",
    "    # Divide cada componente del vector de centroide por el número de vectores en esa clase\n",
    "    # para obtener el promedio, que es el centroide.\n",
    "    for c in centroides:\n",
    "        centroides[c] = [x / contador[c] for x in centroides[c]]\n",
    "    \n",
    "    return centroides  # Retorna el diccionario de centroides.\n",
    "        \n",
    "# Esta función clasifica nuevos vectores en X basándose en el centroide más cercano de las clases precalculadas.        \n",
    "def clasificador_minima_distancia(X, centroides):\n",
    "    # X es una lista de vectores a clasificar.\n",
    "    # centroides es un diccionario de centroides precalculados para cada clase.\n",
    "\n",
    "    predicciones = []  # Lista para almacenar las predicciones.\n",
    "\n",
    "    # Itera sobre cada vector en X.\n",
    "    for xi in X:\n",
    "        # Calcula la distancia al cuadrado de xi a cada centroide.\n",
    "        distancias = {c: sum((xi[j] - centroides[c][j])**2 for j in range(len(xi))) for c in centroides}\n",
    "\n",
    "        # Encuentra la clase con la distancia mínima y la agrega a las predicciones.\n",
    "        predicciones.append(min(distancias, key=distancias.get))\n",
    "    \n",
    "    return predicciones  # Retorna la lista de clases predichas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DESARROLLO DE MODELO K NEAREST NEIGHBORS (K=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificador_knn(X_train, y_train, X_test):\n",
    "    # Lista para almacenar las predicciones de las clases para cada punto en X_test\n",
    "    predicciones = []\n",
    "\n",
    "    # Itera sobre cada punto de prueba en X_test\n",
    "    for xi in X_test:\n",
    "        # Calcula la distancia euclidiana cuadrada entre el punto de prueba xi \n",
    "        # y todos los puntos en el conjunto de entrenamiento X_train\n",
    "        distancias = [sum((xi[j] - X_train[i][j])**2 for j in range(len(xi))) \n",
    "                      for i in range(len(X_train))]\n",
    "\n",
    "        # Encuentra el índice del punto más cercano (menor distancia) en X_train\n",
    "        min_index = distancias.index(min(distancias))\n",
    "\n",
    "        # Agrega la etiqueta de clase correspondiente al punto más cercano a las predicciones\n",
    "        predicciones.append(y_train[min_index])\n",
    "\n",
    "    # Devuelve la lista de predicciones para cada punto en X_test\n",
    "    return predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MÉTODOS DE VALIDACIÓN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - DESARROLLO DE MÉTODO TEST-TRAIN SPLIT (80-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenamiento_prueba(X, y, porcentaje_prueba):\n",
    "    # Calcula el índice de corte para dividir los datos en entrenamiento y prueba segun el porcentaje de prueba\n",
    "    indice_corte = int(len(X) * (1 - porcentaje_prueba))\n",
    "\n",
    "    # Divide el conjunto de datos X en dos partes: \n",
    "    # X_train contiene los datos desde el inicio hasta el índice de corte.\n",
    "    # Esto forma el conjunto de entrenamiento.\n",
    "    X_train = X[:indice_corte]\n",
    "\n",
    "    # y_train contiene las etiquetas correspondientes a X_train.\n",
    "    y_train = y[:indice_corte]\n",
    "\n",
    "    # X_test contiene los datos desde el índice de corte hasta el final.\n",
    "    # Esto forma el conjunto de prueba.\n",
    "    X_test = X[indice_corte:]\n",
    "\n",
    "    # y_test contiene las etiquetas correspondientes a X_test.\n",
    "    y_test = y[indice_corte:]\n",
    "\n",
    "    # La función devuelve los conjuntos de entrenamiento y prueba.\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - DESARROLLO DE MÉTODO K-FOLD CROSS VALIDATION (K=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOJO: Un generador es un tipo especial de iterador, que a diferencia de una lista o cualquier colección que almacena todos sus elementos en la memoria, produce elementos uno a la vez y solo cuando se solicitan.\\nManejo de Memoria Eficiente: Los generadores calculan los valores sobre la marcha y los devuelven uno a la vez, lo que ahorra memoria, especialmente útil para procesar grandes cantidades de datos.\\nEstado de Función Suspendido: Cuando se encuentra un yield, el estado de la función se \"congela\", y todas las variables y su estado se mantienen hasta la próxima vez que el generador es llamado.\\nIteración Conveniente: Al usar un generador, no es necesario esperar a que todos los elementos estén disponibles. Se puede comenzar a procesar el primer elemento tan pronto como esté disponible.\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def k_fold_cross_validation(X, y, k):\n",
    "    # Calcular el tamaño de cada fold dividiendo el tamaño total del conjunto de datos por k.\n",
    "    tamaño_fold = len(X) // k\n",
    "\n",
    "    # Iterar k veces para crear k folds diferentes.\n",
    "    for i in range(k):\n",
    "        # Calcular los índices de inicio y fin para el conjunto de prueba.\n",
    "        # el inicio va desde 0 hasta el tamaño del fold multiplicado por el numero de iteracion\n",
    "        inicio = i * tamaño_fold\n",
    "        # el fin va desde el inicio mas el tamaño del fold hasta el tamaño del fold multiplicado por el numero de iteracion mas 1\n",
    "        fin = (i + 1) * tamaño_fold if i != k - 1 else len(X)\n",
    "\n",
    "        # Crear el conjunto de entrenamiento excluyendo los datos del conjunto de prueba actual.\n",
    "        X_train = X[:inicio] + X[fin:]\n",
    "        y_train = y[:inicio] + y[fin:]\n",
    "\n",
    "        # Crear el conjunto de prueba para la iteración actual.\n",
    "        X_test = X[inicio:fin]\n",
    "        y_test = y[inicio:fin]\n",
    "\n",
    "        # 'yield' devuelve un generador que produce una serie de conjuntos de entrenamiento y prueba.\n",
    "        yield X_train, y_train, X_test, y_test\n",
    "\"\"\"\n",
    "OJO: Un generador es un tipo especial de iterador, que a diferencia de una lista o cualquier colección que almacena todos sus elementos en la memoria, produce elementos uno a la vez y solo cuando se solicitan.\n",
    "Manejo de Memoria Eficiente: Los generadores calculan los valores sobre la marcha y los devuelven uno a la vez, lo que ahorra memoria, especialmente útil para procesar grandes cantidades de datos.\n",
    "Estado de Función Suspendido: Cuando se encuentra un yield, el estado de la función se \"congela\", y todas las variables y su estado se mantienen hasta la próxima vez que el generador es llamado.\n",
    "Iteración Conveniente: Al usar un generador, no es necesario esperar a que todos los elementos estén disponibles. Se puede comenzar a procesar el primer elemento tan pronto como esté disponible.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - DESARROLLO DE MÉTODO BOOTSTRAPPING (B=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def bootstrap(X, y, n):\n",
    "    # Este bucle se ejecuta 'n' veces. En cada iteración, se realiza un proceso de remuestreo.\n",
    "    for _ in range(n):\n",
    "        # Se generan índices aleatorios para el conjunto de entrenamiento.\n",
    "        # La longitud de la lista de índices es igual a la longitud de 'X'.\n",
    "        # 'random.randint(0, len(X) - 1)' genera un índice aleatorio entre 0 y len(X)-1.\n",
    "        indices = [random.randint(0, len(X) - 1) for _ in range(len(X))]\n",
    "\n",
    "        # Se crean los conjuntos de entrenamiento.\n",
    "        # 'X_train' contiene elementos de 'X' en las posiciones indicadas por 'indices'.\n",
    "        # 'y_train' contiene elementos de 'y' en las mismas posiciones.\n",
    "        X_train = [X[i] for i in indices]\n",
    "        y_train = [y[i] for i in indices]\n",
    "\n",
    "        # Se crean los conjuntos de prueba.\n",
    "        # 'X_test' y 'y_test' contienen elementos de 'X' y 'y' que no están en los índices de entrenamiento.\n",
    "        X_test = [X[i] for i in range(len(X)) if i not in indices]\n",
    "        y_test = [y[i] for i in range(len(X)) if i not in indices]\n",
    "\n",
    "        # La función 'yield' devuelve los conjuntos de entrenamiento y prueba.\n",
    "        # En cada iteración del bucle, se devuelve un nuevo conjunto de remuestreo.\n",
    "        yield X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCIONES AUXILIARES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - FUNCION PARA CALCULAR LA RELACIÓN EFIENCIA-ERROR DE UN MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_eficiencia_error(y_real, y_pred):\n",
    "    # Se inicializa un contador para los valores correctos\n",
    "    correctos = sum(1 for real, pred in zip(y_real, y_pred) if real == pred)\n",
    "    # La eficiencia se calcula como la proporción de predicciones correctas\n",
    "    eficiencia = correctos / len(y_real)\n",
    "    # El error se calcula como el complemento de la eficiencia\n",
    "    error = 1 - eficiencia\n",
    "    # La función devuelve tanto la eficiencia como el error\n",
    "    return eficiencia, error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - FUNCION PARA TRANSFORMAR UN DATAFRAME EN UNA LISTA DE LISTAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformar_datos(vector_x, vector_y):\n",
    "    # Convierte el vector_x en una lista. \n",
    "    # Supone que vector_x es una estructura de datos como un DataFrame de pandas,\n",
    "    # y utiliza el método .values.tolist() para convertirlo en una lista de Python.\n",
    "    X = vector_x.values.tolist() \n",
    "\n",
    "    # Realiza la misma conversión para vector_y, transformándolo en una lista.\n",
    "    y = vector_y.values.tolist()\n",
    "\n",
    "    # Comprueba si el primer elemento de y es una lista.\n",
    "    # Si es así, se asume que y es una lista de listas, y se procede a \"aplanar\" esta lista.\n",
    "    # Esto se hace mediante una comprensión de lista que toma el primer elemento de cada sublista.\n",
    "    # Por ejemplo, si y = [[1], [2], [3]], esto se convierte en [1, 2, 3].\n",
    "    # Si y no es una lista de listas, se mantiene como está.\n",
    "    y = [item[0] for item in y] if isinstance(y[0], list) else y\n",
    "\n",
    "    # Devuelve las listas X y y transformadas.\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### 4 => CONTENEDOR DE EJECUCIÓN DE MODELO: DISTANCIA MINIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_min_distance_model(X, y):\n",
    "    # ENTRENAMIENTO Y PRUEBA\n",
    "    X_train, y_train, X_test, y_test = entrenamiento_prueba(X, y, porcentaje_prueba=0.2)\n",
    "    # Calcular centroides y hacer predicciones\n",
    "    centroides = calcular_centroides(X_train, y_train)\n",
    "    predicciones = clasificador_minima_distancia(X_test, centroides)\n",
    "    # Calcular eficiencia y error\n",
    "    eficiencia, error = calcular_eficiencia_error(y_test, predicciones)\n",
    "    print(f\"Minima distancia: eficiencia = {eficiencia}, error = {error} - Metodo de entrenamiento y prueba\")\n",
    "    \n",
    "    # K-FOLD CROSS VALIDATION\n",
    "    eficiencias = []\n",
    "    errores = []\n",
    "    k = 5  # Número de folds\n",
    "    for X_train, y_train, X_test, y_test in k_fold_cross_validation(X, y, k):\n",
    "        centroides = calcular_centroides(X_train, y_train)\n",
    "        predicciones = clasificador_minima_distancia(X_test, centroides)\n",
    "        eficiencia, error = calcular_eficiencia_error(y_test, predicciones)\n",
    "        eficiencias.append(eficiencia)\n",
    "        errores.append(error)\n",
    "    # Calcular promedios\n",
    "    eficiencia_promedio = sum(eficiencias) / k\n",
    "    error_promedio = sum(errores) / k\n",
    "    print(f\"Minima distancia: eficiencia = {eficiencia_promedio}, error = {error_promedio} - K-fold cross validation\")\n",
    "    \n",
    "    # BOOTSTRAP\n",
    "    eficiencias = []\n",
    "    errores = []\n",
    "    n_iteraciones = 100  # Número de iteraciones de Bootstrap\n",
    "    for X_train, y_train, X_test, y_test in bootstrap(X, y, n_iteraciones):\n",
    "        centroides = calcular_centroides(X_train, y_train)\n",
    "        predicciones = clasificador_minima_distancia(X_test, centroides)\n",
    "        eficiencia, error = calcular_eficiencia_error(y_test, predicciones)\n",
    "        eficiencias.append(eficiencia)\n",
    "        errores.append(error)\n",
    "    # Calcular promedios\n",
    "    eficiencia_promedio = sum(eficiencias) / n_iteraciones\n",
    "    error_promedio = sum(errores) / n_iteraciones\n",
    "    print(f\"Minima distancia: eficiencia = {eficiencia_promedio}, error = {error_promedio} - Bootstrap\")      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_min_distance_model(X, y):\n",
    "    # ENTRENAMIENTO Y PRUEBA\n",
    "    # Esta línea divide los datos en conjuntos de entrenamiento y prueba.\n",
    "    # X_train y y_train son los datos y etiquetas de entrenamiento respectivamente.\n",
    "    # X_test y y_test son los datos y etiquetas de prueba respectivamente.\n",
    "    # El parámetro porcentaje_prueba=0.2 indica que el 20% de los datos se utilizarán para la prueba.\n",
    "    X_train, y_train, X_test, y_test = entrenamiento_prueba(X, y, porcentaje_prueba=0.2)\n",
    "\n",
    "    # Calcular centroides y hacer predicciones\n",
    "    # Esta función calcula los centroides de los grupos en los datos de entrenamiento.\n",
    "    centroides = calcular_centroides(X_train, y_train)\n",
    "    # Esta función clasifica los datos de prueba basándose en la distancia mínima a los centroides.\n",
    "    predicciones = clasificador_minima_distancia(X_test, centroides)\n",
    "\n",
    "    # Calcular eficiencia y error\n",
    "    # Esta función calcula la eficiencia y el error del modelo en los datos de prueba.\n",
    "    eficiencia, error = calcular_eficiencia_error(y_test, predicciones)\n",
    "    print(f\"Minima distancia: eficiencia = {eficiencia}, error = {error} - Metodo de entrenamiento y prueba\")\n",
    "    \n",
    "    # K-FOLD CROSS VALIDATION\n",
    "    # Inicialización de listas para almacenar eficiencias y errores en cada iteración de K-fold.\n",
    "    eficiencias = []\n",
    "    errores = []\n",
    "    k = 5  # Número de folds\n",
    "\n",
    "    # Este bucle itera a través de las particiones creadas por el método K-fold.\n",
    "    for X_train, y_train, X_test, y_test in k_fold_cross_validation(X, y, k):\n",
    "        centroides = calcular_centroides(X_train, y_train)\n",
    "        predicciones = clasificador_minima_distancia(X_test, centroides)\n",
    "        eficiencia, error = calcular_eficiencia_error(y_test, predicciones)\n",
    "        eficiencias.append(eficiencia)\n",
    "        errores.append(error)\n",
    "\n",
    "    # Calcular promedios de eficiencia y error para K-fold.\n",
    "    eficiencia_promedio = sum(eficiencias) / k\n",
    "    error_promedio = sum(errores) / k\n",
    "    print(f\"Minima distancia: eficiencia = {eficiencia_promedio}, error = {error_promedio} - K-fold cross validation\")\n",
    "    \n",
    "    # BOOTSTRAP\n",
    "    # Inicialización de listas para almacenar eficiencias y errores en cada iteración de Bootstrap.\n",
    "    eficiencias = []\n",
    "    errores = []\n",
    "    n_iteraciones = 100  # Número de iteraciones de Bootstrap\n",
    "\n",
    "    # Este bucle realiza el método Bootstrap con el número especificado de iteraciones.\n",
    "    for X_train, y_train, X_test, y_test in bootstrap(X, y, n_iteraciones):\n",
    "        centroides = calcular_centroides(X_train, y_train)\n",
    "        predicciones = clasificador_minima_distancia(X_test, centroides)\n",
    "        eficiencia, error = calcular_eficiencia_error(y_test, predicciones)\n",
    "        eficiencias.append(eficiencia)\n",
    "        errores.append(error)\n",
    "\n",
    "    # Calcular promedios de eficiencia y error para Bootstrap.\n",
    "    eficiencia_promedio = sum(eficiencias) / n_iteraciones\n",
    "    error_promedio = sum(errores) / n_iteraciones\n",
    "    print(f\"Minima distancia: eficiencia = {eficiencia_promedio}, error = {error_promedio} - Bootstrap\")      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### 5 => CONTENDOR DE EJECUCIÓN DE MODELO: KNN(K=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_knn_model(X, y):\n",
    "    # ENTRENAMIENTO Y PRUEBA\n",
    "    # Dividir los datos\n",
    "    X_train, y_train, X_test, y_test = entrenamiento_prueba(X, y, porcentaje_prueba=0.2)\n",
    "    # Hacer predicciones\n",
    "    predicciones = clasificador_knn(X_train, y_train, X_test)\n",
    "    # Calcular eficiencia y error\n",
    "    eficiencia, error = calcular_eficiencia_error(y_test, predicciones)\n",
    "    print(f\"KNN: eficiencia = {eficiencia}, error = {error} - Metodo de entrenamiento y prueba\")\n",
    "    \n",
    "    # K-FOLD CROSS VALIDATION\n",
    "    eficiencias = []\n",
    "    errores = []\n",
    "    k = 5  # Número de folds\n",
    "    for X_train, y_train, X_test, y_test in k_fold_cross_validation(X, y, k):\n",
    "        predicciones = clasificador_knn(X_train, y_train, X_test)\n",
    "        eficiencia, error = calcular_eficiencia_error(y_test, predicciones)\n",
    "        eficiencias.append(eficiencia)\n",
    "        errores.append(error)\n",
    "    # Calcular promedios\n",
    "    eficiencia_promedio = sum(eficiencias) / k\n",
    "    error_promedio = sum(errores) / k\n",
    "    print(f\"KNN: eficiencia = {eficiencia_promedio}, error = {error_promedio} - K-fold cross validation\")\n",
    "    \n",
    "    # BOOTSTRAP\n",
    "    eficiencias = []\n",
    "    errores = []\n",
    "    n_iteraciones = 10  # Número de iteraciones de Bootstrap\n",
    "    for X_train, y_train, X_test, y_test in bootstrap(X, y, n_iteraciones):\n",
    "        predicciones = clasificador_knn(X_train, y_train, X_test)\n",
    "        eficiencia, error = calcular_eficiencia_error(y_test, predicciones)\n",
    "        eficiencias.append(eficiencia)\n",
    "        errores.append(error)\n",
    "    # Calcular promedios\n",
    "    eficiencia_promedio = sum(eficiencias) / n_iteraciones\n",
    "    error_promedio = sum(errores) / n_iteraciones\n",
    "    print(f\"KNN: eficiencia = {eficiencia_promedio}, error = {error_promedio} - Bootstrap\")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_knn_model(X, y):\n",
    "    # ENTRENAMIENTO Y PRUEBA\n",
    "\n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba. \n",
    "    # Un 20% de los datos se usa para prueba, el resto para entrenamiento.\n",
    "    X_train, y_train, X_test, y_test = entrenamiento_prueba(X, y, porcentaje_prueba=0.2)\n",
    "    \n",
    "    # Hacer predicciones usando el clasificador KNN con los datos de entrenamiento y evaluar en los de prueba.\n",
    "    predicciones = clasificador_knn(X_train, y_train, X_test)\n",
    "    \n",
    "    # Calcular la eficiencia y el error del modelo en base a las predicciones y los verdaderos valores de prueba.\n",
    "    eficiencia, error = calcular_eficiencia_error(y_test, predicciones)\n",
    "    print(f\"KNN: eficiencia = {eficiencia}, error = {error} - Metodo de entrenamiento y prueba\")\n",
    "    \n",
    "    # K-FOLD CROSS VALIDATION\n",
    "\n",
    "    # Inicialización de listas para almacenar las eficiencias y errores de cada fold.\n",
    "    eficiencias = []\n",
    "    errores = []\n",
    "    k = 5  # Número de folds en la validación cruzada.\n",
    "\n",
    "    # Iterar sobre cada conjunto de entrenamiento y prueba proporcionado por K-Fold Cross Validation.\n",
    "    for X_train, y_train, X_test, y_test in k_fold_cross_validation(X, y, k):\n",
    "        predicciones = clasificador_knn(X_train, y_train, X_test)\n",
    "        eficiencia, error = calcular_eficiencia_error(y_test, predicciones)\n",
    "        eficiencias.append(eficiencia)\n",
    "        errores.append(error)\n",
    "    \n",
    "    # Calcular el promedio de eficiencia y error a través de todos los folds.\n",
    "    eficiencia_promedio = sum(eficiencias) / k\n",
    "    error_promedio = sum(errores) / k\n",
    "    print(f\"KNN: eficiencia = {eficiencia_promedio}, error = {error_promedio} - K-fold cross validation\")\n",
    "    \n",
    "    # BOOTSTRAP\n",
    "\n",
    "    # Inicialización de listas para almacenar las eficiencias y errores de cada iteración de Bootstrap.\n",
    "    eficiencias = []\n",
    "    errores = []\n",
    "    n_iteraciones = 10  # Número de iteraciones de Bootstrap.\n",
    "\n",
    "    # Iterar sobre cada conjunto de entrenamiento y prueba generado por el método Bootstrap.\n",
    "    for X_train, y_train, X_test, y_test in bootstrap(X, y, n_iteraciones):\n",
    "        predicciones = clasificador_knn(X_train, y_train, X_test)\n",
    "        eficiencia, error = calcular_eficiencia_error(y_test, predicciones)\n",
    "        eficiencias.append(eficiencia)\n",
    "        errores.append(error)\n",
    "    \n",
    "    # Calcular el promedio de eficiencia y error a través de todas las iteraciones de Bootstrap.\n",
    "    eficiencia_promedio = sum(eficiencias) / n_iteraciones\n",
    "    error_promedio = sum(errores) / n_iteraciones\n",
    "    print(f\"KNN: eficiencia = {eficiencia_promedio}, error = {error_promedio} - Bootstrap\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EJECUCIÓN DE MODELOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformamos los vectores de entrada y salida a listas\n",
    "X, y = transformar_datos(vector_x, vector_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# PASO 4: EJECUCIÓN DE DISTANCIA MINIMA\n",
    "- #### 4.A => DISTANCIA MINIMA - EVALUADO CON: TRAIN-TEST SPLIT\n",
    "- #### 4.B => DISTANCIA MINIMA - EVALUADO CON: K FOLD CROSS VALIDATION\n",
    "- #### 4.C => DISTANCIA MINIMA - EVALUADO CON: BOOTSTRAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minima distancia: eficiencia = 0.18208092485549132, error = 0.8179190751445087 - Metodo de entrenamiento y prueba\n",
      "Minima distancia: eficiencia = 0.22229385307346328, error = 0.7777061469265367 - K-fold cross validation\n",
      "Minima distancia: eficiencia = 0.1762940884661652, error = 0.8237059115338345 - Bootstrap\n"
     ]
    }
   ],
   "source": [
    "# ejecutamos el modelo de distancia minima y validamos internamente con cada metodo\n",
    "run_min_distance_model(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# PASO 5: EJECUCIÓN DE KNN(K=1)\n",
    "- #### 5.A => KNN - EVALUADO CON: TRAIN-TEST SPLIT\n",
    "- #### 5.B => KNN - EVALUADO CON: K FOLD CROSS VALIDATION\n",
    "- #### 5.C => KNN - EVALUADO CON: BOOTSTRAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: eficiencia = 0.5722543352601156, error = 0.4277456647398844 - Metodo de entrenamiento y prueba\n",
      "KNN: eficiencia = 0.7004497751124438, error = 0.2995502248875562 - K-fold cross validation\n",
      "KNN: eficiencia = 0.5548984654730735, error = 0.44510153452692647 - Bootstrap\n"
     ]
    }
   ],
   "source": [
    "# ejecutamos el modelo de KNN y validamos internamente con cada metodo\n",
    "run_knn_model(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# PASO 6: ELIMINACIÓN DE ATRIBUTOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# seleccionamos el atributo 1 (columna) de mi vector_x de entradas\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m atributo_1 \u001b[38;5;241m=\u001b[39m \u001b[43mvector_x\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# seleccionamos el atributo 2 (columna) de mi vector_x de entradas\u001b[39;00m\n\u001b[0;32m      4\u001b[0m atributo_2 \u001b[38;5;241m=\u001b[39m vector_x\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:5174\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(key) \u001b[38;5;129;01mor\u001b[39;00m is_float(key):\n\u001b[0;32m   5172\u001b[0m     \u001b[38;5;66;03m# GH#44051 exclude bool, which would return a 2d ndarray\u001b[39;00m\n\u001b[0;32m   5173\u001b[0m     key \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mcast_scalar_indexer(key)\n\u001b[1;32m-> 5174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n\u001b[0;32m   5177\u001b[0m     \u001b[38;5;66;03m# This case is separated from the conditional above to avoid\u001b[39;00m\n\u001b[0;32m   5178\u001b[0m     \u001b[38;5;66;03m# pessimization com.is_bool_indexer and ndim checks.\u001b[39;00m\n\u001b[0;32m   5179\u001b[0m     result \u001b[38;5;241m=\u001b[39m getitem(key)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# seleccionamos el atributo 1 (columna) de mi vector_x de entradas\n",
    "atributo_1 = vector_x.columns[1]\n",
    "# seleccionamos el atributo 2 (columna) de mi vector_x de entradas\n",
    "atributo_2 = vector_x.columns[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminamos el atributo_1 pero de un vector de entradas de prueba\n",
    "vector_x_prueba_1 = vector_x.drop(atributo_1, axis=1)\n",
    "\n",
    "# repetimos proceso para hacer test de modelo\n",
    "X, y = transformar_datos(vector_x_prueba_1, vector_y)\n",
    "run_min_distance_model(X, y)\n",
    "run_knn_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminamos el atributo_2 de mi vector de entradas pero de un vector de entradas de prueba 2\n",
    "vector_x_prueba_2 = vector_x.drop(atributo_2, axis=1)\n",
    "\n",
    "# repetimos proceso para hacer test de modelo\n",
    "X, y = transformar_datos(vector_x_prueba_2, vector_y)\n",
    "run_min_distance_model(X, y)\n",
    "run_knn_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminamos los atributos 1 y 2 de mi vector de entradas pero de un vector de entradas de prueba 3\n",
    "vector_x_prueba_3 = vector_x.drop([atributo_1, atributo_2], axis=1)\n",
    "\n",
    "# repetimos proceso para hacer test de modelo\n",
    "X, y = transformar_datos(vector_x_prueba_3, vector_y)\n",
    "run_min_distance_model(X, y)\n",
    "run_knn_model(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
